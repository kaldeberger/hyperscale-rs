//! Hyperscale Validator Node
//!
//! Production binary for running a validator node.
//!
//! # Usage
//!
//! ```bash
//! # Start with configuration file
//! hyperscale-validator --config validator.toml
//!
//! # Override data directory
//! hyperscale-validator --config validator.toml --data-dir /var/lib/hyperscale
//!
//! # Specify signing key path
//! hyperscale-validator --config validator.toml --key /etc/hyperscale/validator.key
//! ```
//!
//! # Configuration
//!
//! See `ValidatorConfig` for all configuration options. Example TOML:
//!
//! ```toml
//! [node]
//! validator_id = 0
//! shard = 0
//! data_dir = "./data"
//!
//! [network]
//! listen_addr = "/ip4/0.0.0.0/udp/9000/quic-v1"
//! bootstrap_peers = []
//!
//! [consensus]
//! proposal_interval_ms = 300
//! view_change_timeout_ms = 3000
//!
//! [threads]
//! crypto_threads = 4
//! execution_threads = 8
//! io_threads = 2
//!
//! [metrics]
//! enabled = true
//! listen_addr = "0.0.0.0:9090"
//! ```

use anyhow::{bail, Context, Result};
use clap::Parser;
use hyperscale_bft::BftConfig;
use hyperscale_core::Event;
use hyperscale_production::network::{derive_libp2p_keypair, Libp2pConfig};
use hyperscale_production::rpc::{RpcServer, RpcServerConfig};
use hyperscale_production::{
    init_telemetry, ProductionRunner, RocksDbConfig, RocksDbStorage, TelemetryConfig,
    ThreadPoolConfig, ThreadPoolManager,
};
use hyperscale_types::{
    KeyPair, KeyType, PublicKey, ShardGroupId, StaticTopology, ValidatorId, ValidatorInfo,
    ValidatorSet,
};
use parking_lot::RwLock;
use radix_common::network::NetworkDefinition;
use radix_common::prelude::AddressBech32Decoder;
use serde::Deserialize;
use std::fs;
use std::path::PathBuf;
use std::sync::Arc;
use std::time::Duration;
use tokio::signal;
use tracing::{info, warn};
use tracing_subscriber::EnvFilter;

/// Hyperscale Validator Node
///
/// Runs a production validator participating in BFT consensus.
#[derive(Parser, Debug)]
#[command(name = "hyperscale-validator")]
#[command(version, about, long_about = None)]
struct Cli {
    /// Path to configuration file (TOML)
    #[arg(short, long)]
    config: PathBuf,

    /// Path to validator signing key (overrides config)
    #[arg(long)]
    key: Option<PathBuf>,

    /// Data directory for RocksDB (overrides config)
    #[arg(long)]
    data_dir: Option<PathBuf>,

    /// Metrics listen address (overrides config)
    #[arg(long)]
    metrics_addr: Option<String>,

    /// Bootstrap peer multiaddresses (can be specified multiple times)
    #[arg(long)]
    bootstrap: Vec<String>,

    /// Log level filter (overrides RUST_LOG)
    #[arg(long, default_value = "info")]
    log_level: String,
}

/// Top-level validator configuration.
#[derive(Debug, Clone, Deserialize)]
pub struct ValidatorConfig {
    /// Node identity configuration
    pub node: NodeConfig,

    /// Network configuration
    #[serde(default)]
    pub network: NetworkConfig,

    /// Consensus configuration
    #[serde(default)]
    pub consensus: ConsensusConfig,

    /// Thread pool configuration
    #[serde(default)]
    pub threads: ThreadsConfig,

    /// Storage configuration
    #[serde(default)]
    pub storage: StorageConfig,

    /// Metrics configuration
    #[serde(default)]
    pub metrics: MetricsConfig,

    /// Telemetry configuration
    #[serde(default)]
    pub telemetry: TelemetryConfigToml,

    /// Genesis configuration (validators in the network)
    #[serde(default)]
    pub genesis: GenesisConfig,
}

/// Node identity configuration.
#[derive(Debug, Clone, Deserialize)]
pub struct NodeConfig {
    /// Validator ID (index in the committee)
    pub validator_id: u64,

    /// Shard group this validator belongs to
    #[serde(default)]
    pub shard: u64,

    /// Number of shards in the network
    #[serde(default = "default_num_shards")]
    pub num_shards: u64,

    /// Path to the signing key file
    #[serde(default)]
    pub key_path: Option<PathBuf>,

    /// Data directory for storage
    #[serde(default = "default_data_dir")]
    pub data_dir: PathBuf,
}

fn default_num_shards() -> u64 {
    1
}

fn default_data_dir() -> PathBuf {
    PathBuf::from("./data")
}

/// Network configuration.
#[derive(Debug, Clone, Deserialize, Default)]
pub struct NetworkConfig {
    /// Listen address (multiaddr format)
    #[serde(default = "default_listen_addr")]
    pub listen_addr: String,

    /// Bootstrap peer addresses
    #[serde(default)]
    pub bootstrap_peers: Vec<String>,

    /// Request timeout in milliseconds
    #[serde(default = "default_request_timeout_ms")]
    pub request_timeout_ms: u64,

    /// Maximum message size in bytes
    #[serde(default = "default_max_message_size")]
    pub max_message_size: usize,

    /// Gossipsub heartbeat interval in milliseconds
    #[serde(default = "default_gossipsub_heartbeat_ms")]
    pub gossipsub_heartbeat_ms: u64,
}

fn default_listen_addr() -> String {
    "/ip4/0.0.0.0/udp/9000/quic-v1".to_string()
}

fn default_request_timeout_ms() -> u64 {
    30_000
}

fn default_max_message_size() -> usize {
    65536
}

fn default_gossipsub_heartbeat_ms() -> u64 {
    100
}

/// Consensus configuration.
#[derive(Debug, Clone, Deserialize)]
pub struct ConsensusConfig {
    /// Interval between proposal attempts (milliseconds)
    #[serde(default = "default_proposal_interval_ms")]
    pub proposal_interval_ms: u64,

    /// Timeout for view change (milliseconds)
    #[serde(default = "default_view_change_timeout_ms")]
    pub view_change_timeout_ms: u64,

    /// Maximum transactions per block
    #[serde(default = "default_max_transactions_per_block")]
    pub max_transactions_per_block: usize,

    /// Maximum certificates per block
    #[serde(default = "default_max_certificates_per_block")]
    pub max_certificates_per_block: usize,
}

impl Default for ConsensusConfig {
    fn default() -> Self {
        Self {
            proposal_interval_ms: default_proposal_interval_ms(),
            view_change_timeout_ms: default_view_change_timeout_ms(),
            max_transactions_per_block: default_max_transactions_per_block(),
            max_certificates_per_block: default_max_certificates_per_block(),
        }
    }
}

fn default_proposal_interval_ms() -> u64 {
    300
}

fn default_view_change_timeout_ms() -> u64 {
    3000
}

fn default_max_transactions_per_block() -> usize {
    4096
}

fn default_max_certificates_per_block() -> usize {
    4096
}

/// Thread pool configuration.
#[derive(Debug, Clone, Deserialize, Default)]
pub struct ThreadsConfig {
    /// Number of crypto verification threads (0 = auto)
    #[serde(default)]
    pub crypto_threads: usize,

    /// Number of execution threads (0 = auto)
    #[serde(default)]
    pub execution_threads: usize,

    /// Number of I/O threads (0 = auto)
    #[serde(default)]
    pub io_threads: usize,

    /// Enable CPU core pinning (Linux only)
    #[serde(default)]
    pub pin_cores: bool,
}

/// Compression type for storage (maps to RocksDB compression).
#[derive(Debug, Clone, Copy, Default, Deserialize)]
#[serde(rename_all = "lowercase")]
pub enum CompressionType {
    None,
    Snappy,
    Zlib,
    #[default]
    Lz4,
    Lz4hc,
    Zstd,
}

impl From<CompressionType> for hyperscale_production::CompressionType {
    fn from(ct: CompressionType) -> Self {
        match ct {
            CompressionType::None => hyperscale_production::CompressionType::None,
            CompressionType::Snappy => hyperscale_production::CompressionType::Snappy,
            CompressionType::Zlib => hyperscale_production::CompressionType::Zlib,
            CompressionType::Lz4 => hyperscale_production::CompressionType::Lz4,
            CompressionType::Lz4hc => hyperscale_production::CompressionType::Lz4hc,
            CompressionType::Zstd => hyperscale_production::CompressionType::Zstd,
        }
    }
}

/// Storage configuration.
#[derive(Debug, Clone, Deserialize)]
pub struct StorageConfig {
    /// Maximum background jobs for RocksDB
    #[serde(default = "default_max_background_jobs")]
    pub max_background_jobs: i32,

    /// Write buffer size in MB
    #[serde(default = "default_write_buffer_mb")]
    pub write_buffer_mb: usize,

    /// Maximum number of write buffers
    #[serde(default = "default_max_write_buffer_number")]
    pub max_write_buffer_number: i32,

    /// Block cache size in MB (0 to disable)
    #[serde(default = "default_block_cache_mb")]
    pub block_cache_mb: usize,

    /// Compression type (none, snappy, zlib, lz4, lz4hc, zstd)
    #[serde(default)]
    pub compression: CompressionType,

    /// Bloom filter bits per key (0 to disable)
    #[serde(default = "default_bloom_filter_bits")]
    pub bloom_filter_bits: f64,

    /// Bytes per sync in MB (0 to disable)
    #[serde(default = "default_bytes_per_sync_mb")]
    pub bytes_per_sync_mb: usize,

    /// Number of log files to keep
    #[serde(default = "default_keep_log_file_num")]
    pub keep_log_file_num: usize,
}

impl Default for StorageConfig {
    fn default() -> Self {
        Self {
            max_background_jobs: default_max_background_jobs(),
            write_buffer_mb: default_write_buffer_mb(),
            max_write_buffer_number: default_max_write_buffer_number(),
            block_cache_mb: default_block_cache_mb(),
            compression: CompressionType::default(),
            bloom_filter_bits: default_bloom_filter_bits(),
            bytes_per_sync_mb: default_bytes_per_sync_mb(),
            keep_log_file_num: default_keep_log_file_num(),
        }
    }
}

fn default_max_background_jobs() -> i32 {
    4
}

fn default_write_buffer_mb() -> usize {
    128
}

fn default_max_write_buffer_number() -> i32 {
    3
}

fn default_block_cache_mb() -> usize {
    512
}

fn default_bloom_filter_bits() -> f64 {
    10.0
}

fn default_bytes_per_sync_mb() -> usize {
    1
}

fn default_keep_log_file_num() -> usize {
    10
}

/// Metrics configuration.
#[derive(Debug, Clone, Deserialize)]
pub struct MetricsConfig {
    /// Enable metrics endpoint
    #[serde(default = "default_metrics_enabled")]
    pub enabled: bool,

    /// Metrics HTTP listen address
    #[serde(default = "default_metrics_addr")]
    pub listen_addr: String,
}

impl Default for MetricsConfig {
    fn default() -> Self {
        Self {
            enabled: default_metrics_enabled(),
            listen_addr: default_metrics_addr(),
        }
    }
}

fn default_metrics_enabled() -> bool {
    true
}

fn default_metrics_addr() -> String {
    "0.0.0.0:9090".to_string()
}

/// Telemetry configuration.
#[derive(Debug, Clone, Deserialize, Default)]
pub struct TelemetryConfigToml {
    /// Enable OpenTelemetry tracing
    #[serde(default)]
    pub enabled: bool,

    /// OTLP endpoint for traces
    #[serde(default)]
    pub otlp_endpoint: Option<String>,

    /// Service name for tracing
    #[serde(default = "default_service_name")]
    pub service_name: String,
}

fn default_service_name() -> String {
    "hyperscale-validator".to_string()
}

/// Genesis configuration defining the validator set and initial balances.
#[derive(Debug, Clone, Deserialize, Default)]
pub struct GenesisConfig {
    /// Validators in the network
    #[serde(default)]
    pub validators: Vec<ValidatorEntry>,

    /// Initial XRD balances for accounts
    #[serde(default)]
    pub xrd_balances: Vec<XrdBalanceEntry>,
}

/// An XRD balance entry for genesis configuration.
#[derive(Debug, Clone, Deserialize)]
pub struct XrdBalanceEntry {
    /// Bech32-encoded account address (e.g., "account_sim1...")
    pub address: String,

    /// Balance as a string (parsed as Decimal)
    pub balance: String,
}

/// A validator entry in genesis configuration.
#[derive(Debug, Clone, Deserialize)]
pub struct ValidatorEntry {
    /// Validator ID
    pub id: u64,

    /// Shard this validator belongs to
    #[serde(default)]
    pub shard: Option<u64>,

    /// Hex-encoded public key
    pub public_key: String,

    /// Voting power (default: 1)
    #[serde(default = "default_voting_power")]
    pub voting_power: u64,
}

fn default_voting_power() -> u64 {
    1
}

impl ValidatorConfig {
    /// Load configuration from a TOML file.
    pub fn load(path: &PathBuf) -> Result<Self> {
        let contents = fs::read_to_string(path)
            .with_context(|| format!("Failed to read config file: {}", path.display()))?;

        toml::from_str(&contents)
            .with_context(|| format!("Failed to parse config file: {}", path.display()))
    }

    /// Apply CLI overrides to the configuration.
    fn apply_overrides(&mut self, cli: &Cli) {
        if let Some(ref key_path) = cli.key {
            self.node.key_path = Some(key_path.clone());
        }

        if let Some(ref data_dir) = cli.data_dir {
            self.node.data_dir = data_dir.clone();
        }

        if let Some(ref metrics_addr) = cli.metrics_addr {
            self.metrics.listen_addr = metrics_addr.clone();
        }

        if !cli.bootstrap.is_empty() {
            self.network.bootstrap_peers.extend(cli.bootstrap.clone());
        }
    }
}

/// Format a public key as a hex string.
fn format_public_key(pk: &PublicKey) -> String {
    match pk {
        PublicKey::Ed25519(bytes) => hex::encode(bytes),
        PublicKey::Bls12381(bytes) => hex::encode(bytes),
    }
}

/// Load or generate a signing keypair.
///
/// The key file stores a 32-byte seed that deterministically generates the keypair.
/// This seed can be stored as raw bytes or hex-encoded.
fn load_or_generate_keypair(key_path: Option<&PathBuf>) -> Result<KeyPair> {
    match key_path {
        Some(path) => {
            if path.exists() {
                let key_bytes = fs::read(path)
                    .with_context(|| format!("Failed to read key file: {}", path.display()))?;

                // Try to decode as hex first, then as raw bytes
                let decoded = if key_bytes.len() == 64 {
                    // Likely hex-encoded (64 hex chars = 32 bytes)
                    hex::decode(&key_bytes).with_context(|| "Failed to decode hex key")?
                } else if key_bytes.len() == 32 {
                    // Raw bytes
                    key_bytes
                } else {
                    bail!(
                        "Invalid key file size: expected 32 bytes (raw) or 64 hex chars, got {} bytes",
                        key_bytes.len()
                    );
                };

                // Convert to fixed array
                let seed: [u8; 32] = decoded
                    .try_into()
                    .map_err(|_| anyhow::anyhow!("Key must be exactly 32 bytes"))?;

                // Use BLS12-381 for consensus (supports signature aggregation)
                Ok(KeyPair::from_seed(KeyType::Bls12381, &seed))
            } else {
                info!("Key file not found, generating new keypair");

                // Generate random seed
                let mut seed = [0u8; 32];
                use rand::RngCore;
                rand::rngs::OsRng.fill_bytes(&mut seed);

                let keypair = KeyPair::from_seed(KeyType::Bls12381, &seed);

                // Save the seed
                if let Some(parent) = path.parent() {
                    fs::create_dir_all(parent)?;
                }
                fs::write(path, seed)?;
                info!("Saved new keypair seed to {}", path.display());

                Ok(keypair)
            }
        }
        None => {
            warn!("No key path specified, generating ephemeral keypair");
            Ok(KeyPair::generate_bls())
        }
    }
}

/// Build the topology from genesis configuration.
fn build_topology(
    config: &ValidatorConfig,
    local_keypair: &KeyPair,
) -> Result<Arc<dyn hyperscale_types::Topology>> {
    use std::collections::HashMap;

    let local_validator_id = ValidatorId(config.node.validator_id);
    let local_shard = ShardGroupId(config.node.shard);
    let num_shards = config.node.num_shards;

    // Build validator set from genesis config
    let validators: Vec<ValidatorInfo> = if config.genesis.validators.is_empty() {
        // Single validator mode (development/testing)
        warn!("No validators in genesis config, running in single-validator mode");
        vec![ValidatorInfo {
            validator_id: local_validator_id,
            public_key: local_keypair.public_key(),
            voting_power: 1,
        }]
    } else {
        config
            .genesis
            .validators
            .iter()
            .map(|v| {
                let public_key = if v.id == config.node.validator_id {
                    // Use our own key for our validator ID
                    local_keypair.public_key()
                } else {
                    // Parse hex-encoded public key
                    let key_bytes = hex::decode(&v.public_key)
                        .with_context(|| format!("Invalid hex public key for validator {}", v.id))?;

                    // Ed25519 public keys are 32 bytes
                    if key_bytes.len() == 32 {
                        let bytes: [u8; 32] = key_bytes
                            .try_into()
                            .map_err(|_| anyhow::anyhow!("Invalid public key length"))?;
                        PublicKey::Ed25519(bytes)
                    } else if key_bytes.len() == 48 {
                        // BLS12-381 public key (compressed)
                        PublicKey::Bls12381(key_bytes)
                    } else {
                        bail!(
                            "Invalid public key length for validator {}: expected 32 (Ed25519) or 48 (BLS), got {}",
                            v.id,
                            key_bytes.len()
                        );
                    }
                };

                Ok(ValidatorInfo {
                    validator_id: ValidatorId(v.id),
                    public_key,
                    voting_power: v.voting_power,
                })
            })
            .collect::<Result<Vec<_>>>()?
    };

    let validator_set = ValidatorSet::new(validators);

    // Check if validators have explicit shard assignments
    let has_shard_assignments = config.genesis.validators.iter().any(|v| v.shard.is_some());

    if has_shard_assignments {
        // Build shard committees from explicit shard assignments in config
        // This is required for multi-shard setups where each validator needs to know
        // about ALL validators across ALL shards for cross-shard message verification
        let mut shard_committees: HashMap<ShardGroupId, Vec<ValidatorId>> = HashMap::new();

        for v in &config.genesis.validators {
            // Use explicit shard if provided, otherwise fall back to validator_id % num_shards
            let shard = ShardGroupId(v.shard.unwrap_or(v.id % num_shards));
            shard_committees
                .entry(shard)
                .or_default()
                .push(ValidatorId(v.id));
        }

        info!(
            num_shards = num_shards,
            total_validators = config.genesis.validators.len(),
            "Building topology with explicit shard assignments"
        );

        Ok(StaticTopology::with_shard_committees(
            local_validator_id,
            local_shard,
            num_shards,
            &validator_set,
            shard_committees,
        )
        .into_arc())
    } else {
        // Legacy mode: all validators in genesis belong to local shard only
        // This only works for single-shard deployments
        if num_shards > 1 {
            warn!(
                "Multi-shard deployment without explicit shard assignments in genesis config. \
                 Cross-shard messages may fail. Add 'shard = N' to each [[genesis.validators]] entry."
            );
        }

        Ok(StaticTopology::with_local_shard(
            local_validator_id,
            local_shard,
            num_shards,
            validator_set,
        )
        .into_arc())
    }
}

/// Build engine genesis configuration from TOML config.
///
/// Converts the TOML-friendly genesis config (with string addresses and balances)
/// to the engine's GenesisConfig type.
fn build_engine_genesis_config(config: &GenesisConfig) -> Result<hyperscale_engine::GenesisConfig> {
    use radix_common::math::Decimal;
    use radix_common::types::ComponentAddress;
    use std::str::FromStr;

    let network = NetworkDefinition::simulator();
    let decoder = AddressBech32Decoder::new(&network);

    let mut engine_config = hyperscale_engine::GenesisConfig::test_default();

    // Convert XRD balances
    for entry in &config.xrd_balances {
        // Decode bech32 address
        let (_, address_bytes) = decoder
            .validate_and_decode(&entry.address)
            .map_err(|e| anyhow::anyhow!("Invalid address '{}': {:?}", entry.address, e))?;

        let address = ComponentAddress::try_from(address_bytes.as_slice()).map_err(|e| {
            anyhow::anyhow!("Invalid component address '{}': {:?}", entry.address, e)
        })?;

        // Parse balance
        let balance = Decimal::from_str(&entry.balance)
            .map_err(|e| anyhow::anyhow!("Invalid balance '{}': {:?}", entry.balance, e))?;

        engine_config.xrd_balances.push((address, balance));
    }

    info!(
        xrd_balances = engine_config.xrd_balances.len(),
        "Parsed genesis XRD balances"
    );

    Ok(engine_config)
}

/// Build thread pool configuration from TOML config.
fn build_thread_pool_config(config: &ThreadsConfig) -> ThreadPoolConfig {
    let mut builder = ThreadPoolConfig::builder();

    if config.crypto_threads > 0 {
        builder = builder.crypto_threads(config.crypto_threads);
    }
    if config.execution_threads > 0 {
        builder = builder.execution_threads(config.execution_threads);
    }
    if config.io_threads > 0 {
        builder = builder.io_threads(config.io_threads);
    }
    if config.pin_cores {
        builder = builder.pin_cores(true);
    }

    builder.build_unchecked()
}

/// Build BFT configuration from TOML config.
fn build_bft_config(config: &ConsensusConfig) -> BftConfig {
    BftConfig::new()
        .with_proposal_interval(Duration::from_millis(config.proposal_interval_ms))
        .with_view_change_timeout(Duration::from_millis(config.view_change_timeout_ms))
        .with_max_transactions(config.max_transactions_per_block)
}

/// Build network configuration from TOML config.
fn build_network_config(config: &NetworkConfig) -> Result<Libp2pConfig> {
    let listen_addr = config
        .listen_addr
        .parse()
        .with_context(|| format!("Invalid listen address: {}", config.listen_addr))?;

    let bootstrap_peers: Vec<_> = config
        .bootstrap_peers
        .iter()
        .filter_map(|addr| {
            addr.parse().ok().or_else(|| {
                warn!("Invalid bootstrap peer address: {}", addr);
                None
            })
        })
        .collect();

    Ok(Libp2pConfig::default()
        .with_listen_addresses(vec![listen_addr])
        .with_bootstrap_peers(bootstrap_peers)
        .with_request_timeout(Duration::from_millis(config.request_timeout_ms))
        .with_max_message_size(config.max_message_size)
        .with_gossipsub_heartbeat(Duration::from_millis(config.gossipsub_heartbeat_ms)))
}

/// Build RocksDB configuration from TOML config.
fn build_rocksdb_config(config: &StorageConfig) -> RocksDbConfig {
    RocksDbConfig {
        max_background_jobs: config.max_background_jobs,
        write_buffer_size: config.write_buffer_mb * 1024 * 1024,
        max_write_buffer_number: config.max_write_buffer_number,
        block_cache_size: if config.block_cache_mb > 0 {
            Some(config.block_cache_mb * 1024 * 1024)
        } else {
            None
        },
        compression: config.compression.into(),
        bloom_filter_bits: config.bloom_filter_bits,
        bytes_per_sync: config.bytes_per_sync_mb * 1024 * 1024,
        keep_log_file_num: config.keep_log_file_num,
        ..RocksDbConfig::default()
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    let cli = Cli::parse();

    // Initialize logging
    tracing_subscriber::fmt()
        .with_env_filter(
            EnvFilter::try_from_default_env().unwrap_or_else(|_| EnvFilter::new(&cli.log_level)),
        )
        .init();

    info!("Hyperscale Validator starting...");

    // Load configuration
    let mut config = ValidatorConfig::load(&cli.config)?;
    config.apply_overrides(&cli);

    info!(
        validator_id = config.node.validator_id,
        shard = config.node.shard,
        num_shards = config.node.num_shards,
        "Node configuration loaded"
    );

    // Initialize telemetry if enabled
    let _telemetry_guard = if config.telemetry.enabled {
        let telemetry_config = TelemetryConfig {
            service_name: config.telemetry.service_name.clone(),
            otlp_endpoint: config.telemetry.otlp_endpoint.clone(),
            sampling_ratio: 1.0,
            prometheus_enabled: false, // We handle metrics separately
            prometheus_port: 9090,
            resource_attributes: vec![
                (
                    "validator_id".to_string(),
                    config.node.validator_id.to_string(),
                ),
                ("shard".to_string(), config.node.shard.to_string()),
            ],
        };
        Some(init_telemetry(&telemetry_config)?)
    } else {
        None
    };

    // Ensure data directory exists
    fs::create_dir_all(&config.node.data_dir)?;

    // Load or generate keys
    let signing_keypair = load_or_generate_keypair(config.node.key_path.as_ref())?;
    info!(
        public_key = %format_public_key(&signing_keypair.public_key()),
        "Loaded signing keypair"
    );

    // Derive libp2p identity deterministically from signing key
    // This ensures PeerIds are predictable and can be computed from public keys
    let p2p_identity = derive_libp2p_keypair(&signing_keypair.public_key());
    info!(
        peer_id = %p2p_identity.public().to_peer_id(),
        "Derived p2p identity from signing key"
    );

    // Build topology
    let topology = build_topology(&config, &signing_keypair)?;
    info!(
        committee_size = topology.local_committee_size(),
        quorum_threshold = topology.local_quorum_threshold(),
        "Topology initialized"
    );

    // Build configurations
    let thread_config = build_thread_pool_config(&config.threads);
    let bft_config = build_bft_config(&config.consensus);
    let network_config = build_network_config(&config.network)?;
    let rocksdb_config = build_rocksdb_config(&config.storage);

    // Initialize thread pools
    let thread_pools = Arc::new(
        ThreadPoolManager::new(thread_config).context("Failed to initialize thread pools")?,
    );

    // Open storage
    let db_path = config.node.data_dir.join("db");
    let storage = RocksDbStorage::open_with_config(&db_path, rocksdb_config)
        .with_context(|| format!("Failed to open database at {}", db_path.display()))?;
    let storage = Arc::new(RwLock::new(storage));
    info!("Storage opened at {}", db_path.display());

    // Create transaction submission channel for RPC server
    let (tx_sender, mut tx_receiver) = tokio::sync::mpsc::channel(1000);

    // Create transaction validator for signature verification
    let tx_validator = Arc::new(hyperscale_engine::TransactionValidation::new(
        NetworkDefinition::simulator(),
    ));

    // Start RPC server
    let rpc_handle = if config.metrics.enabled {
        let rpc_config = RpcServerConfig {
            listen_addr: config.metrics.listen_addr.parse().with_context(|| {
                format!(
                    "Invalid metrics listen address: {}",
                    config.metrics.listen_addr
                )
            })?,
            metrics_enabled: true,
        };

        let rpc_server = RpcServer::new(rpc_config, tx_sender, tx_validator.clone());
        let handle = rpc_server
            .start()
            .await
            .context("Failed to start RPC server")?;

        // Update node status with initial values
        {
            let mut status = handle.node_status().write().await;
            status.validator_id = config.node.validator_id;
            status.shard = config.node.shard;
            status.num_shards = config.node.num_shards;
        }

        Some(handle)
    } else {
        None
    };

    // Create production runner
    let mut runner_builder = ProductionRunner::builder()
        .topology(topology)
        .signing_key(signing_keypair)
        .bft_config(bft_config)
        .thread_pools(thread_pools)
        .storage(storage)
        .network(network_config, p2p_identity);

    // Wire up RPC status updates if RPC server is enabled
    if let Some(ref handle) = rpc_handle {
        runner_builder = runner_builder
            .rpc_status(handle.node_status().clone())
            .tx_status_cache(handle.tx_status_cache().clone())
            .mempool_snapshot(handle.mempool_snapshot().clone());
    }

    // Wire up genesis configuration if XRD balances are specified
    if !config.genesis.xrd_balances.is_empty() {
        let engine_genesis = build_engine_genesis_config(&config.genesis)
            .context("Failed to parse genesis configuration")?;
        runner_builder = runner_builder.genesis_config(engine_genesis);
    }

    let mut runner = runner_builder
        .build()
        .await
        .context("Failed to create production runner")?;

    // Get event sender for transaction injection
    let event_sender = runner.event_sender();

    // Get shutdown handle
    let shutdown_handle = runner.shutdown_handle();

    // Spawn transaction forwarder (RPC -> event loop)
    tokio::spawn(async move {
        while let Some(tx) = tx_receiver.recv().await {
            // Submit transaction via the proper submit path (emits status updates)
            if let Err(e) = event_sender
                .send(Event::SubmitTransaction {
                    tx: std::sync::Arc::new(tx),
                })
                .await
            {
                warn!("Failed to forward RPC transaction: {}", e);
            }
        }
    });

    // Spawn shutdown signal handler
    tokio::spawn(async move {
        let ctrl_c = async {
            signal::ctrl_c()
                .await
                .expect("Failed to install Ctrl+C handler");
        };

        #[cfg(unix)]
        let terminate = async {
            signal::unix::signal(signal::unix::SignalKind::terminate())
                .expect("Failed to install signal handler")
                .recv()
                .await;
        };

        #[cfg(not(unix))]
        let terminate = std::future::pending::<()>();

        tokio::select! {
            _ = ctrl_c => info!("Received Ctrl+C"),
            _ = terminate => info!("Received SIGTERM"),
        }

        if let Some(handle) = shutdown_handle {
            info!("Initiating graceful shutdown...");
            handle.shutdown();
        }
    });

    // Mark node as ready
    if let Some(ref handle) = rpc_handle {
        handle.set_ready(true);
    }

    info!("Validator node started, press Ctrl+C to stop");

    // Run the main event loop
    if let Err(e) = runner.run().await {
        bail!("Runner error: {}", e);
    }

    // Cleanup RPC server
    if let Some(handle) = rpc_handle {
        handle.abort();
    }

    info!("Validator shutdown complete");
    Ok(())
}
