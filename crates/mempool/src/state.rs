//! Mempool state.

use hyperscale_core::{
    Action, Event, OutboundMessage, RequestId, SubStateMachine, TransactionStatus,
};
use hyperscale_types::{
    AbortReason, Block, BlockHeight, DeferReason, Hash, NodeId, RoutableTransaction,
    TransactionAbort, TransactionDecision,
};
use std::collections::{HashMap, HashSet};
use std::time::Duration;
use tracing::instrument;

/// Lock contention statistics from the mempool.
#[derive(Clone, Copy, Debug, Default)]
pub struct LockContentionStats {
    /// Number of nodes currently locked by in-flight transactions.
    pub locked_nodes: u64,
    /// Number of transactions blocked waiting for a winner to complete.
    pub blocked_count: u64,
    /// Number of transactions in Pending status.
    pub pending_count: u64,
    /// Number of pending transactions that conflict with locked nodes.
    pub pending_blocked: u64,
}

impl LockContentionStats {
    /// Contention ratio: what fraction of pending transactions are blocked.
    pub fn contention_ratio(&self) -> f64 {
        if self.pending_count > 0 {
            self.pending_blocked as f64 / self.pending_count as f64
        } else {
            0.0
        }
    }
}

/// Entry in the transaction pool.
#[derive(Debug)]
struct PoolEntry {
    tx: RoutableTransaction,
    status: TransactionStatus,
    #[allow(dead_code)]
    added_at: Duration,
}

/// Mempool state machine.
///
/// Handles transaction lifecycle from submission to completion.
/// Uses `HashMap` instead of `DashMap` since access is serialized.
#[derive(Debug)]
pub struct MempoolState {
    /// Transaction pool (HashMap, not DashMap - no concurrent access).
    pool: HashMap<Hash, PoolEntry>,

    /// Blocked transactions waiting for their winner to complete.
    /// Maps: loser_tx_hash -> (loser_tx, winner_tx_hash)
    ///
    /// When a deferral commits, the loser is added here with status Blocked.
    /// When the winner's certificate commits, we create a retry.
    blocked_by: HashMap<Hash, (RoutableTransaction, Hash)>,

    /// Current time.
    now: Duration,
}

impl MempoolState {
    /// Create a new mempool state machine.
    pub fn new() -> Self {
        Self {
            pool: HashMap::new(),
            blocked_by: HashMap::new(),
            now: Duration::ZERO,
        }
    }

    /// Handle transaction submission from client.
    #[instrument(skip(self, tx), fields(tx_hash = ?tx.hash()))]
    pub fn on_submit_transaction(
        &mut self,
        tx: RoutableTransaction,
        request_id: RequestId,
    ) -> Vec<Action> {
        let hash = tx.hash();

        // Check for duplicate
        if self.pool.contains_key(&hash) {
            return vec![Action::EmitTransactionStatus {
                request_id,
                tx_hash: hash,
                status: TransactionStatus::Pending, // Already exists
            }];
        }

        // Add to pool
        self.pool.insert(
            hash,
            PoolEntry {
                tx: tx.clone(),
                status: TransactionStatus::Pending,
                added_at: self.now,
            },
        );
        tracing::info!(tx_hash = ?hash, pool_size = self.pool.len(), "Transaction added to mempool via submit");

        // Return actions: accept the transaction, broadcast to peers, and notify client
        let actions = vec![
            Action::EnqueueInternal {
                event: Event::TransactionAccepted { tx_hash: hash },
            },
            // Broadcast to all validators globally so cross-shard TXs reach all shards
            Action::BroadcastGlobal {
                message: OutboundMessage::TransactionGossip(Box::new(
                    hyperscale_messages::TransactionGossip::new(tx),
                )),
            },
            Action::EmitTransactionStatus {
                request_id,
                tx_hash: hash,
                status: TransactionStatus::Pending,
            },
        ];
        actions
    }

    /// Handle transaction received via gossip.
    #[instrument(skip(self, tx), fields(tx_hash = ?tx.hash()))]
    pub fn on_transaction_gossip(&mut self, tx: RoutableTransaction) -> Vec<Action> {
        let hash = tx.hash();

        // Ignore if already have it
        if self.pool.contains_key(&hash) {
            return vec![];
        }

        // Add to pool
        self.pool.insert(
            hash,
            PoolEntry {
                tx,
                status: TransactionStatus::Pending,
                added_at: self.now,
            },
        );

        vec![Action::EnqueueInternal {
            event: Event::TransactionAccepted { tx_hash: hash },
        }]
    }

    /// Process a committed block - update statuses and trigger retries.
    ///
    /// This handles:
    /// 1. Mark committed transactions
    /// 2. Process deferrals → update status to Blocked
    /// 3. Process certificates → mark completed, trigger retries for blocked TXs
    /// 4. Process aborts → update status to terminal
    #[instrument(skip(self, block), fields(
        height = block.header.height.0,
        tx_count = block.transactions.len()
    ))]
    pub fn on_block_committed_full(&mut self, block: &Block) -> Vec<Action> {
        let height = block.header.height;
        let mut actions = Vec::new();

        // 1. Mark transactions as committed
        for tx in &block.transactions {
            if let Some(entry) = self.pool.get_mut(&tx.hash()) {
                entry.status = TransactionStatus::Committed(height);
            }
        }

        // 2. Process deferrals - update status to Blocked
        for deferral in &block.deferred {
            actions.extend(self.on_deferral_committed(deferral.tx_hash, &deferral.reason, height));
        }

        // 3. Process certificates - mark completed, trigger retries
        for cert in &block.committed_certificates {
            actions.extend(self.on_certificate_committed(cert.transaction_hash, height));
        }

        // 4. Process aborts - mark as terminal state
        for abort in &block.aborted {
            if let Some(entry) = self.pool.get_mut(&abort.tx_hash) {
                // Transition to a terminal state (we don't have an Aborted status,
                // so we'll use Completed for now - the abort info is in the block)
                entry.status = TransactionStatus::Completed;
            }
        }

        actions
    }

    /// Handle a deferral committed in a block.
    ///
    /// Updates the deferred TX's status to Blocked and tracks it for retry.
    fn on_deferral_committed(
        &mut self,
        tx_hash: Hash,
        reason: &DeferReason,
        _height: BlockHeight,
    ) -> Vec<Action> {
        let DeferReason::LivelockCycle { winner_tx_hash } = reason;

        // Get the transaction and update its status
        if let Some(entry) = self.pool.get_mut(&tx_hash) {
            // Update status to Blocked
            let new_status = TransactionStatus::Blocked {
                by: *winner_tx_hash,
            };
            if entry.status.can_transition_to(&new_status) {
                tracing::info!(
                    tx_hash = %tx_hash,
                    winner = %winner_tx_hash,
                    from = %entry.status,
                    "Transaction deferred due to livelock cycle"
                );
                entry.status = new_status;

                // Track for retry when winner completes
                self.blocked_by
                    .insert(tx_hash, (entry.tx.clone(), *winner_tx_hash));
            }
        }

        vec![]
    }

    /// Handle a certificate committed in a block.
    ///
    /// Marks the transaction as completed and triggers retries for any TXs blocked by it.
    fn on_certificate_committed(&mut self, tx_hash: Hash, height: BlockHeight) -> Vec<Action> {
        let mut actions = Vec::new();

        // Mark the certificate's TX as completed
        if let Some(entry) = self.pool.get_mut(&tx_hash) {
            entry.status = TransactionStatus::Completed;
        }

        // Check if any blocked TXs were waiting for this winner
        let blocked_losers: Vec<_> = self
            .blocked_by
            .iter()
            .filter(|(_, (_, winner))| *winner == tx_hash)
            .map(|(loser_hash, (loser_tx, winner_hash))| {
                (*loser_hash, loser_tx.clone(), *winner_hash)
            })
            .collect();

        for (loser_hash, loser_tx, winner_hash) in blocked_losers {
            // Create retry transaction
            let retry_tx = loser_tx.create_retry(winner_hash, height);
            let retry_hash = retry_tx.hash();

            tracing::info!(
                original = %loser_hash,
                retry = %retry_hash,
                winner = %winner_hash,
                retry_count = retry_tx.retry_count(),
                "Creating retry for deferred transaction"
            );

            // Update original's status to Retried
            if let Some(entry) = self.pool.get_mut(&loser_hash) {
                entry.status = TransactionStatus::Retried { new_tx: retry_hash };
            }

            // Remove from blocked tracking
            self.blocked_by.remove(&loser_hash);

            // Add retry to mempool if not already present (dedup by hash)
            if !self.pool.contains_key(&retry_hash) {
                self.pool.insert(
                    retry_hash,
                    PoolEntry {
                        tx: retry_tx.clone(),
                        status: TransactionStatus::Pending,
                        added_at: self.now,
                    },
                );

                // Gossip the retry to other nodes
                let gossip = hyperscale_messages::TransactionGossip::new(retry_tx);
                actions.push(Action::BroadcastGlobal {
                    message: OutboundMessage::TransactionGossip(Box::new(gossip)),
                });
            }
        }

        actions
    }

    /// Mark transactions as committed when block is committed (legacy method).
    #[deprecated(note = "Use on_block_committed_full instead")]
    pub fn on_block_committed(&mut self, tx_hashes: &[Hash], height: BlockHeight) {
        for hash in tx_hashes {
            if let Some(entry) = self.pool.get_mut(hash) {
                entry.status = TransactionStatus::Committed(height);
            }
        }
    }

    /// Mark a transaction as finalized (execution complete).
    ///
    /// Called when ExecutionState creates a TransactionCertificate.
    #[instrument(skip(self), fields(tx_hash = ?tx_hash, accepted = accepted))]
    pub fn on_transaction_finalized(&mut self, tx_hash: Hash, accepted: bool) -> Vec<Action> {
        if let Some(entry) = self.pool.get_mut(&tx_hash) {
            let decision = if accepted {
                TransactionDecision::Accept
            } else {
                TransactionDecision::Reject
            };
            entry.status = TransactionStatus::Finalized(decision);
        }
        vec![]
    }

    /// Mark a transaction as completed (certificate committed in block).
    ///
    /// This is the terminal state - the transaction can be evicted from mempool.
    pub fn mark_completed(&mut self, tx_hash: &Hash) {
        if let Some(entry) = self.pool.get_mut(tx_hash) {
            entry.status = TransactionStatus::Completed;
        }
    }

    /// Update transaction status to a new state.
    ///
    /// This is used by the execution state machine to update status during
    /// the transaction lifecycle (Provisioning, Executing, etc.).
    pub fn update_status(&mut self, tx_hash: &Hash, new_status: TransactionStatus) {
        if let Some(entry) = self.pool.get_mut(tx_hash) {
            // Validate transition
            if entry.status.can_transition_to(&new_status) {
                tracing::debug!(
                    tx_hash = ?tx_hash,
                    from = %entry.status,
                    to = %new_status,
                    "Transaction status transition"
                );
                entry.status = new_status;
            } else {
                tracing::warn!(
                    tx_hash = ?tx_hash,
                    from = %entry.status,
                    to = %new_status,
                    "Invalid transaction status transition"
                );
            }
        }
    }

    /// Get all NodeIds that are currently locked by in-flight transactions.
    ///
    /// A node is locked if any transaction that declares it (read or write)
    /// is in a lock-holding state (Accepted through Finalized).
    fn locked_nodes(&self) -> HashSet<NodeId> {
        self.pool
            .values()
            .filter(|e| e.status.holds_state_lock())
            .flat_map(|e| e.tx.all_declared_nodes().cloned())
            .collect()
    }

    /// Check if a transaction conflicts with any locked nodes.
    fn conflicts_with_locked(&self, tx: &RoutableTransaction, locked: &HashSet<NodeId>) -> bool {
        tx.all_declared_nodes().any(|node| locked.contains(node))
    }

    /// Get transactions ready for inclusion in a block.
    ///
    /// Returns transactions that are:
    /// 1. In Pending status (not yet accepted)
    /// 2. Do not conflict with any in-flight transaction (no shared nodes)
    /// 3. Sorted by hash (ascending) to reduce cross-shard conflicts
    ///
    /// The hash-ordering ensures different shards are more likely to pick
    /// the same transactions, reducing cycle formation in cross-shard execution.
    pub fn ready_transactions(&self, max_count: usize) -> Vec<RoutableTransaction> {
        // Get all nodes currently locked by in-flight transactions
        let locked = self.locked_nodes();

        // Collect pending transactions that don't conflict
        let mut ready: Vec<_> = self
            .pool
            .values()
            .filter(|e| e.status == TransactionStatus::Pending)
            .filter(|e| !self.conflicts_with_locked(&e.tx, &locked))
            .map(|e| e.tx.clone())
            .collect();

        // Sort by hash (ascending) - lower hashes are selected first
        // This makes different shards more likely to select the same TXs,
        // reducing the chance of cross-shard cycles
        ready.sort_by_key(|tx| tx.hash());

        ready.into_iter().take(max_count).collect()
    }

    /// Get lock contention statistics.
    ///
    /// Returns counts of:
    /// - `locked_nodes`: Number of nodes currently locked by in-flight transactions
    /// - `blocked_count`: Number of transactions blocked waiting for a winner
    /// - `pending_count`: Number of transactions in Pending status
    /// - `pending_blocked`: Number of pending transactions that conflict with locked nodes
    pub fn lock_contention_stats(&self) -> LockContentionStats {
        let locked = self.locked_nodes();
        let locked_nodes = locked.len() as u64;
        let blocked_count = self.blocked_by.len() as u64;

        let pending_count = self
            .pool
            .values()
            .filter(|e| e.status == TransactionStatus::Pending)
            .count() as u64;

        let pending_blocked = self
            .pool
            .values()
            .filter(|e| e.status == TransactionStatus::Pending)
            .filter(|e| self.conflicts_with_locked(&e.tx, &locked))
            .count() as u64;

        LockContentionStats {
            locked_nodes,
            blocked_count,
            pending_count,
            pending_blocked,
        }
    }

    /// Check if we have a transaction.
    pub fn has_transaction(&self, hash: &Hash) -> bool {
        self.pool.contains_key(hash)
    }

    /// Get a transaction by hash.
    pub fn get_transaction(&self, hash: &Hash) -> Option<&RoutableTransaction> {
        self.pool.get(hash).map(|e| &e.tx)
    }

    /// Get transaction status.
    pub fn status(&self, hash: &Hash) -> Option<TransactionStatus> {
        self.pool.get(hash).map(|e| e.status.clone())
    }

    /// Get all transactions as a HashMap (for block header validation).
    ///
    /// This allows BFT to look up transactions by hash when receiving block headers.
    pub fn transactions_by_hash(&self) -> HashMap<Hash, RoutableTransaction> {
        self.pool
            .iter()
            .map(|(hash, entry)| (*hash, entry.tx.clone()))
            .collect()
    }

    /// Get the number of transactions in the pool.
    pub fn len(&self) -> usize {
        self.pool.len()
    }

    /// Get the mempool as a hash map for BFT pending block completion.
    pub fn as_hash_map(&self) -> std::collections::HashMap<Hash, RoutableTransaction> {
        self.pool
            .iter()
            .map(|(hash, entry)| (*hash, entry.tx.clone()))
            .collect()
    }

    /// Check if the pool is empty.
    pub fn is_empty(&self) -> bool {
        self.pool.is_empty()
    }

    /// Get all incomplete transactions (not yet finalized or completed).
    ///
    /// Returns tuples of (hash, status, transaction) for analysis.
    pub fn incomplete_transactions(&self) -> Vec<(Hash, TransactionStatus, RoutableTransaction)> {
        self.pool
            .iter()
            .filter(|(_, entry)| {
                !matches!(
                    entry.status,
                    TransactionStatus::Finalized(_) | TransactionStatus::Completed
                )
            })
            .map(|(hash, entry)| (*hash, entry.status.clone(), entry.tx.clone()))
            .collect()
    }

    /// Get transactions that have timed out waiting for execution.
    ///
    /// Transactions timeout if they've been holding state locks for too long.
    /// This is a safety net for N-way cycles that aren't detected by pairwise
    /// cycle detection.
    ///
    /// Returns `TransactionAbort` entries ready for inclusion in a block.
    ///
    /// # Parameters
    /// - `current_height`: The current block height
    /// - `timeout_blocks`: Number of blocks after which a TX is considered timed out
    /// - `max_retries`: Maximum retry count before aborting
    pub fn get_timed_out_transactions(
        &self,
        current_height: BlockHeight,
        timeout_blocks: u64,
        max_retries: u32,
    ) -> Vec<TransactionAbort> {
        let mut aborts = Vec::new();

        for (hash, entry) in &self.pool {
            // Skip transactions that are already finalized or completed
            if matches!(
                entry.status,
                TransactionStatus::Finalized(_) | TransactionStatus::Completed
            ) {
                continue;
            }

            // Check for execution timeout (TX stuck in lock-holding state too long)
            if let TransactionStatus::Committed(committed_at) = &entry.status {
                let blocks_elapsed = current_height.0.saturating_sub(committed_at.0);
                if blocks_elapsed >= timeout_blocks {
                    tracing::info!(
                        tx_hash = %hash,
                        committed_at = committed_at.0,
                        current_height = current_height.0,
                        blocks_elapsed = blocks_elapsed,
                        "Transaction timed out waiting for execution"
                    );
                    aborts.push(TransactionAbort {
                        tx_hash: *hash,
                        reason: AbortReason::ExecutionTimeout {
                            committed_at: *committed_at,
                        },
                        block_height: BlockHeight(0), // Filled in by proposer
                    });
                }
            }

            // Also check other lock-holding states
            // (Provisioning, Provisioned, Executing, Finalizing)
            // These don't have committed_at embedded, so we'd need to track
            // when they entered these states. For now, only handle Committed.

            // Check for too many retries
            if entry.tx.exceeds_max_retries(max_retries) {
                tracing::info!(
                    tx_hash = %hash,
                    retry_count = entry.tx.retry_count(),
                    max_retries = max_retries,
                    "Transaction exceeded maximum retry count"
                );
                aborts.push(TransactionAbort {
                    tx_hash: *hash,
                    reason: AbortReason::TooManyRetries {
                        retry_count: entry.tx.retry_count(),
                    },
                    block_height: BlockHeight(0), // Filled in by proposer
                });
            }
        }

        aborts
    }
}

impl Default for MempoolState {
    fn default() -> Self {
        Self::new()
    }
}

impl SubStateMachine for MempoolState {
    fn try_handle(&mut self, event: &Event) -> Option<Vec<Action>> {
        match event {
            Event::SubmitTransaction { tx, request_id } => {
                Some(self.on_submit_transaction(tx.clone(), *request_id))
            }
            Event::TransactionGossipReceived { tx } => Some(self.on_transaction_gossip(tx.clone())),
            Event::BlockCommitted { block, .. } => {
                // Process block fully including deferrals, certificates, and aborts
                Some(self.on_block_committed_full(block))
            }
            Event::TransactionFinalized { tx_hash, accepted } => {
                Some(self.on_transaction_finalized(*tx_hash, *accepted))
            }
            // Handle status update events from execution
            Event::TransactionStatusChanged { tx_hash, status } => {
                self.update_status(tx_hash, status.clone());
                Some(vec![])
            }
            _ => None,
        }
    }

    fn set_time(&mut self, now: Duration) {
        self.now = now;
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use hyperscale_core::RequestId;
    use hyperscale_types::{
        test_utils::test_transaction, Block, BlockHeader, DeferReason, QuorumCertificate,
        TransactionCertificate, TransactionDefer, ValidatorId,
    };
    use std::collections::BTreeMap;

    fn make_test_block(
        height: u64,
        transactions: Vec<RoutableTransaction>,
        deferred: Vec<TransactionDefer>,
        certificates: Vec<TransactionCertificate>,
        aborted: Vec<TransactionAbort>,
    ) -> Block {
        Block {
            header: BlockHeader {
                height: BlockHeight(height),
                parent_hash: Hash::from_bytes(b"parent"),
                parent_qc: QuorumCertificate::genesis(),
                proposer: ValidatorId(0),
                timestamp: 1234567890,
                round: 0,
                is_fallback: false,
            },
            transactions,
            committed_certificates: certificates,
            deferred,
            aborted,
        }
    }

    fn make_test_certificate(tx_hash: Hash) -> TransactionCertificate {
        TransactionCertificate {
            transaction_hash: tx_hash,
            decision: TransactionDecision::Accept,
            shard_proofs: BTreeMap::new(), // Empty for test - just need tx_hash
        }
    }

    #[test]
    fn test_deferral_updates_status_to_blocked() {
        let mut mempool = MempoolState::new();

        // Create and add a transaction
        let tx = test_transaction(1);
        let tx_hash = tx.hash();
        mempool.on_submit_transaction(tx.clone(), RequestId(0));

        // Commit the transaction first (deferrals apply to committed TXs)
        let commit_block = make_test_block(1, vec![tx.clone()], vec![], vec![], vec![]);
        mempool.on_block_committed_full(&commit_block);

        // Verify status is Committed
        assert!(matches!(
            mempool.status(&tx_hash),
            Some(TransactionStatus::Committed(_))
        ));

        // Create another TX as the "winner"
        let winner_tx = test_transaction(2);
        let winner_hash = winner_tx.hash();
        mempool.on_submit_transaction(winner_tx.clone(), RequestId(1));

        // Create a deferral for our TX
        let deferral = TransactionDefer {
            tx_hash,
            reason: DeferReason::LivelockCycle {
                winner_tx_hash: winner_hash,
            },
            block_height: BlockHeight(2),
        };

        // Process block with deferral
        let defer_block = make_test_block(2, vec![], vec![deferral], vec![], vec![]);
        mempool.on_block_committed_full(&defer_block);

        // Verify status is now Blocked
        let status = mempool.status(&tx_hash);
        assert!(matches!(
            status,
            Some(TransactionStatus::Blocked { by }) if by == winner_hash
        ));

        // Verify it's tracked in blocked_by
        assert!(mempool.blocked_by.contains_key(&tx_hash));
    }

    #[test]
    fn test_winner_certificate_triggers_retry() {
        let mut mempool = MempoolState::new();

        // Create loser TX and submit
        let loser_tx = test_transaction(1);
        let loser_hash = loser_tx.hash();
        mempool.on_submit_transaction(loser_tx.clone(), RequestId(0));

        // Create winner TX and submit
        let winner_tx = test_transaction(2);
        let winner_hash = winner_tx.hash();
        mempool.on_submit_transaction(winner_tx.clone(), RequestId(1));

        // Commit both
        let commit_block = make_test_block(
            1,
            vec![loser_tx.clone(), winner_tx.clone()],
            vec![],
            vec![],
            vec![],
        );
        mempool.on_block_committed_full(&commit_block);

        // Defer the loser
        let deferral = TransactionDefer {
            tx_hash: loser_hash,
            reason: DeferReason::LivelockCycle {
                winner_tx_hash: winner_hash,
            },
            block_height: BlockHeight(2),
        };
        let defer_block = make_test_block(2, vec![], vec![deferral], vec![], vec![]);
        mempool.on_block_committed_full(&defer_block);

        // Verify loser is blocked
        assert!(matches!(
            mempool.status(&loser_hash),
            Some(TransactionStatus::Blocked { .. })
        ));

        // Winner's certificate commits
        let winner_cert = make_test_certificate(winner_hash);
        let cert_block = make_test_block(3, vec![], vec![], vec![winner_cert], vec![]);
        let actions = mempool.on_block_committed_full(&cert_block);

        // Should have created a retry TX (gossip action)
        assert!(
            !actions.is_empty(),
            "Should have gossiped retry transaction"
        );

        // Loser should now be Retried
        let loser_status = mempool.status(&loser_hash);
        assert!(
            matches!(loser_status, Some(TransactionStatus::Retried { .. })),
            "Loser should be Retried, got {:?}",
            loser_status
        );

        // Retry should exist in pool as Pending
        if let Some(TransactionStatus::Retried { new_tx }) = loser_status {
            let retry_status = mempool.status(&new_tx);
            assert!(
                matches!(retry_status, Some(TransactionStatus::Pending)),
                "Retry should be Pending, got {:?}",
                retry_status
            );
        }

        // blocked_by should be cleared
        assert!(!mempool.blocked_by.contains_key(&loser_hash));
    }

    #[test]
    fn test_timeout_detection() {
        let mut mempool = MempoolState::new();

        // Create and commit a TX
        let tx = test_transaction(1);
        let tx_hash = tx.hash();
        mempool.on_submit_transaction(tx.clone(), RequestId(0));

        let commit_block = make_test_block(1, vec![tx], vec![], vec![], vec![]);
        mempool.on_block_committed_full(&commit_block);

        // Check for timeouts - not enough blocks elapsed
        let aborts = mempool.get_timed_out_transactions(BlockHeight(20), 30, 3);
        assert!(aborts.is_empty(), "Should not timeout yet");

        // Check for timeouts - now enough blocks
        let aborts = mempool.get_timed_out_transactions(BlockHeight(35), 30, 3);
        assert_eq!(aborts.len(), 1);
        assert_eq!(aborts[0].tx_hash, tx_hash);
        assert!(matches!(
            aborts[0].reason,
            AbortReason::ExecutionTimeout { .. }
        ));
    }

    #[test]
    fn test_too_many_retries_detection() {
        let mut mempool = MempoolState::new();

        // Create a TX that has already been retried multiple times
        let tx = test_transaction(1);
        let _tx_hash = tx.hash();

        // Manually create a retry TX (simulating previous retries)
        let retry1 = tx.create_retry(Hash::from_bytes(b"winner1"), BlockHeight(1));
        let retry2 = retry1.create_retry(Hash::from_bytes(b"winner2"), BlockHeight(2));
        let retry3 = retry2.create_retry(Hash::from_bytes(b"winner3"), BlockHeight(3));

        assert_eq!(retry3.retry_count(), 3);

        // Submit the multiply-retried TX
        mempool.on_submit_transaction(retry3.clone(), RequestId(0));

        // Should detect too many retries (max_retries = 3 means 3 retries allowed, 4th would be rejected)
        let aborts = mempool.get_timed_out_transactions(BlockHeight(10), 100, 3);
        assert_eq!(aborts.len(), 1);
        assert!(matches!(
            aborts[0].reason,
            AbortReason::TooManyRetries { retry_count: 3 }
        ));
    }

    #[test]
    fn test_abort_updates_status() {
        let mut mempool = MempoolState::new();

        // Create and commit a TX
        let tx = test_transaction(1);
        let tx_hash = tx.hash();
        mempool.on_submit_transaction(tx.clone(), RequestId(0));

        let commit_block = make_test_block(1, vec![tx], vec![], vec![], vec![]);
        mempool.on_block_committed_full(&commit_block);

        // Process an abort
        let abort = TransactionAbort {
            tx_hash,
            reason: AbortReason::ExecutionTimeout {
                committed_at: BlockHeight(1),
            },
            block_height: BlockHeight(35),
        };
        let abort_block = make_test_block(35, vec![], vec![], vec![], vec![abort]);
        mempool.on_block_committed_full(&abort_block);

        // Status should be Completed (terminal)
        assert!(matches!(
            mempool.status(&tx_hash),
            Some(TransactionStatus::Completed)
        ));
    }

    #[test]
    fn test_retry_has_different_hash() {
        let tx = test_transaction(1);
        let original_hash = tx.hash();

        let retry = tx.create_retry(Hash::from_bytes(b"winner"), BlockHeight(5));
        let retry_hash = retry.hash();

        // Retry must have different hash
        assert_ne!(
            original_hash, retry_hash,
            "Retry must have different hash from original"
        );

        // But same underlying transaction content (declared reads/writes are fields)
        assert_eq!(tx.declared_reads, retry.declared_reads);
        assert_eq!(tx.declared_writes, retry.declared_writes);

        // Retry knows its original
        assert_eq!(retry.original_hash(), original_hash);
        assert_eq!(retry.retry_count(), 1);
    }
}
